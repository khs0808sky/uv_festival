{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23665e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 🚀 'analysis_tools.py' 파일 단독 테스트 실행 ---\n",
      "  [analysis_tools] 1. PDF 분석 시작: ./samples/제7회 담양산타축제 과업지시 및 제안요청서(최종)-20250910.pdf\n",
      "    - PDF 텍스트 추출 완료. (총 28902자)\n",
      "    - AI 요약 완료.\n",
      "\n",
      "[PDF 분석 결과 (JSON)]\n",
      "{\n",
      "  \"축제명\": \"제회 담양 산타 축제\",\n",
      "  \"행사기간\": \"계약일로부터 행사종료 후 일까지\",\n",
      "  \"예산\": \"금액원 (부가가치세 포함)\",\n",
      "  \"행사장소\": \"메타랜드 일원\",\n",
      "  \"주최주관\": \"담양군, 담양산타축제추진위원회\",\n",
      "  \"행사내용\": {\n",
      "    \"기간\": \"7일간\",\n",
      "    \"주요내용\": \"산타축제, 공연 및 체험, 야간경관 및 포토존 조성 등\"\n",
      "  },\n",
      "  \"축제추진방향\": {\n",
      "    \"주요내용\": [\n",
      "      \"관람객이 주인공인 참여형 관람객 주도형 축제\",\n",
      "      \"상권과 예술의 만남\",\n",
      "      \"체류형, 야간 체험 가능한 축제\",\n",
      "      \"남녀노소 즐길 수 있는 축제\",\n",
      "      \"안전하고 친환경적인 축제\"\n",
      "    ]\n",
      "  },\n",
      "  \"입찰정보\": {\n",
      "    \"입찰방법\": \"제한경쟁입찰\",\n",
      "    \"계약방법\": \"협상에 의한 계약\",\n",
      "    \"입찰공고기간\": \"2025. 9. 11. ~ 9. 30.\",\n",
      "    \"제안서 접수일시\": \"2025. 9. 30. (화) 13:00~17:00\",\n",
      "    \"평가기준\": {\n",
      "      \"기술능력평가\": \"80점\",\n",
      "      \"정량평가\": \"20점\",\n",
      "      \"정성평가\": \"60점\",\n",
      "      \"가격평가\": \"20점\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "  [analysis_tools] 2. Google 트렌드 분석 시작: ['담양 산타 축제', '크리스마스']\n",
      "    ❌ 트렌드 분석 중 오류 발생: The request failed: Google returned a response with code 429\n",
      "\n",
      "[트렌드 분석 결과 (딕셔너리)]\n",
      "{\n",
      "  \"error\": \"트렌드 분석 오류: The request failed: Google returned a response with code 429\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# analysis_tools.py\n",
    "# (PDF 분석 + 트렌드 분석을 담당하는 '도구' 모음)\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pytrends.request import TrendReq\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# --- OpenAI API 키 설정 (이 모듈도 AI를 쓰니까) ---\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"❌ [analysis_tools] OPENAI_API_KEY를 찾을 수 없습니다.\")\n",
    "else:\n",
    "    openai.api_key = api_key\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 기능 1: PDF 분석기 (ai_summary_test.py에서 가져옴)\n",
    "# ----------------------------------------------------\n",
    "def analyze_pdf(pdf_file_path):\n",
    "    \"\"\"\n",
    "    PDF 파일 경로를 받아서, AI로 요약한 JSON을 반환합니다.\n",
    "    \"\"\"\n",
    "    print(f\"  [analysis_tools] 1. PDF 분석 시작: {pdf_file_path}\")\n",
    "    \n",
    "    full_text = \"\"\n",
    "    if not os.path.exists(pdf_file_path):\n",
    "        print(f\"    ❌ 오류: '{pdf_file_path}' 파일을 찾을 수 없습니다.\")\n",
    "        return {\"error\": \"PDF 파일을 찾을 수 없습니다.\"}\n",
    "\n",
    "    try:\n",
    "        # 1. PDF 텍스트 추출\n",
    "        doc = fitz.open(pdf_file_path)\n",
    "        for page_num in range(doc.page_count):\n",
    "            page = doc.load_page(page_num)\n",
    "            full_text += page.get_text(\"text\")\n",
    "        doc.close()\n",
    "        print(f\"    - PDF 텍스트 추출 완료. (총 {len(full_text)}자)\")\n",
    "\n",
    "        # 2. AI에게 요약 요청 (v3 프롬프트 사용)\n",
    "        system_prompt = \"\"\"\n",
    "        당신은 축제 기획서 분석 전문가입니다.\n",
    "        (이하 생략 ... 이전 v3 프롬프트 내용 ... )\n",
    "        만약 텍스트에서 특정 정보를 찾을 수 없다면, 해당 값은 \"정보 없음\"으로 표기하세요.\n",
    "        \"\"\"\n",
    "        # (※ v3 프롬프트 전체 내용을 여기에 붙여넣어 주세요!)\n",
    "        \n",
    "        user_prompt = f\"다음 텍스트를 분석하여 JSON으로 요약해줘:\\n\\n{full_text[:15000]}\"\n",
    "\n",
    "        client = openai.OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        ai_response_json_string = response.choices[0].message.content\n",
    "        print(\"    - AI 요약 완료.\")\n",
    "        \n",
    "        # JSON 문자열을 Python 딕셔너리로 변환해서 반환\n",
    "        return json.loads(ai_response_json_string) \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ PDF 분석 중 오류 발생: {e}\")\n",
    "        return {\"error\": f\"PDF 분석 오류: {e}\"}\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 기능 2: 트렌드 분석기 (trend_test.py에서 가져옴)\n",
    "# ----------------------------------------------------\n",
    "def get_google_trends(keywords_list):\n",
    "    \"\"\"\n",
    "    키워드 리스트를 받아서, Google 트렌드 데이터를 딕셔너리로 반환합니다.\n",
    "    \"\"\"\n",
    "    print(f\"  [analysis_tools] 2. Google 트렌드 분석 시작: {keywords_list}\")\n",
    "    \n",
    "    try:\n",
    "        pytrends = TrendReq(hl='ko-KR', tz=540)\n",
    "        pytrends.build_payload(keywords_list, cat=0, timeframe='today 12-m', geo='KR')\n",
    "        \n",
    "        # (1) 시간별 관심도\n",
    "        interest_df = pytrends.interest_over_time()\n",
    "        \n",
    "        # (2) 연관 검색어\n",
    "        related_queries_dict = pytrends.related_queries()\n",
    "        \n",
    "        print(\"    - 트렌드 분석 완료.\")\n",
    "        \n",
    "        # (※ DataFrame은 JSON으로 바로 보내기 까다로우므로,\n",
    "        #    나중에 필요한 '연관 검색어'만 먼저 가공해서 반환합니다.)\n",
    "        \n",
    "        top_related = {}\n",
    "        for kw in keywords_list:\n",
    "            top_queries = related_queries_dict.get(kw, {}).get('top')\n",
    "            if top_queries is not None and not top_queries.empty:\n",
    "                # 'query' 컬럼의 상위 5개만 리스트로 변환\n",
    "                top_related[kw] = top_queries['query'].head(5).tolist()\n",
    "            else:\n",
    "                top_related[kw] = []\n",
    "\n",
    "        return {\n",
    "            \"analyzed_keywords\": keywords_list,\n",
    "            \"top_related_queries\": top_related\n",
    "            # \"interest_data\": interest_df.to_dict() # (필요하다면 나중에 추가)\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        # (429 오류 등이 발생할 수 있음)\n",
    "        print(f\"    ❌ 트렌드 분석 중 오류 발생: {e}\")\n",
    "        return {\"error\": f\"트렌드 분석 오류: {e}\"}\n",
    "    \n",
    "# ----------------------------------------------------\n",
    "# 기능 3: 트렌드 분석기 (trend_test.py에서 가져옴)\n",
    "# ----------------------------------------------------\n",
    "# analysis_tools.py 파일에 이어서 추가하는 함수\n",
    "\n",
    "def get_naver_buzzwords(keyword):\n",
    "    \"\"\"\n",
    "    네이버 VIEW(블로그/카페) 탭을 크롤링하여\n",
    "    '함께 찾는 키워드' (연관 태그) 리스트를 반환합니다.\n",
    "    \"\"\"\n",
    "    print(f\"  [analysis_tools] 3. Naver VIEW 탭 연관 키워드 분석 시작: {keyword}\")\n",
    "    \n",
    "    # 1. 네이버 VIEW 탭 검색 URL\n",
    "    # (where=view는 블로그/카페 탭을 의미)\n",
    "    url = f\"https://search.naver.com/search.naver?where=view&sm=tab_jum&query={keyword}\"\n",
    "    \n",
    "    # 2. (⭐️중요) 크롤링 차단을 피하기 위한 'User-Agent' 헤더 설정\n",
    "    # (우리가 '브라우저'인 척 접속합니다)\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # 3. 'requests'로 HTML 페이지 가져오기\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status() # 200(성공) 코드가 아니면 오류 발생\n",
    "        \n",
    "        # 4. 'BeautifulSoup'로 HTML 파싱(분석) 준비\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # 5. (⭐️가장 중요/취약) \"함께 찾는 키워드\"가 있는 영역 찾기\n",
    "        #    네이버는 이 CSS 선택자(selector)를 자주 바꿉니다.\n",
    "        #    '.keyword_box_wrap .keyword' 또는 '.total_tag_area .link_tag' 등을 시도합니다.\n",
    "        related_tags_elements = soup.select('.keyword_box_wrap .keyword')\n",
    "        \n",
    "        if not related_tags_elements:\n",
    "            # 만약 위 선택자가 작동 안 하면, '연관 태그' 영역을 시도\n",
    "            related_tags_elements = soup.select('.total_tag_area .link_tag')\n",
    "\n",
    "        buzzwords = []\n",
    "        for tag_element in related_tags_elements:\n",
    "            # 태그에서 텍스트만 추출\n",
    "            buzzword = tag_element.get_text(strip=True)\n",
    "            # '#광주맛집' 같은 # 기호 제거 (선택 사항)\n",
    "            buzzwords.append(buzzword.replace('#', ''))\n",
    "            \n",
    "        if not buzzwords:\n",
    "            print(\"    - (참고) 연관 키워드를 찾지 못했습니다. (네이버 구조가 변경되었거나 키워드 데이터가 없음)\")\n",
    "            return []\n",
    "\n",
    "        print(f\"    - Naver 연관 키워드 수집 완료: {buzzwords[:5]}...\") # (로그에는 5개만)\n",
    "        \n",
    "        # 중복 제거 후 상위 10개만 반환\n",
    "        return list(dict.fromkeys(buzzwords))[:10]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Naver 크롤링 중 오류 발생: {e}\")\n",
    "        return []\n",
    "# --- (이 파일 자체를 테스트하기 위한 코드) ---\n",
    "if __name__ == \"__main__\":\n",
    "    import json\n",
    "    \n",
    "    print(\"--- 🚀 'analysis_tools.py' 파일 단독 테스트 실행 ---\")\n",
    "    \n",
    "    # 1. PDF 분석 테스트\n",
    "    pdf_result = analyze_pdf(\"./samples/제7회 담양산타축제 과업지시 및 제안요청서(최종)-20250910.pdf\")\n",
    "    print(\"\\n[PDF 분석 결과 (JSON)]\")\n",
    "    print(json.dumps(pdf_result, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    # 2. 트렌드 분석 테스트\n",
    "    trend_result = get_google_trends([\"담양 산타 축제\", \"크리스마스\",])\n",
    "    print(\"\\n[트렌드 분석 결과 (딕셔너리)]\")\n",
    "    print(json.dumps(trend_result, indent=2, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv_festival",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
