{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3424944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 축제명: 담양산타축제\n",
      "탐지된 유형: 대='-' | 중='-' | 세부='문화예술-크리스마스·산타'  | 출처: dataset\n",
      "근거(dataset): 파일=2025.csv, 연번=793, 매칭명=제7회 담양산타축제\n",
      "\n",
      "동일 유형 축제 수: 2\n",
      "\n",
      "[동일 유형 축제 목록]\n",
      "  1. 제13회 유러피안 크리스마스 마켓\n",
      "  2. 2024 유성온천 크리스마스축제\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "🎯 (2024+2025) 세분화된 분류(대/중/세부) 기반 축제 분류 · 근거 · 동일세부유형 리스트\n",
    "- 로드: ./csv/{2024.csv, 2025.csv} (+ /mnt/data 경로도 시도)\n",
    "- 아직 시작 안 한 축제(시작일 > 오늘) 제외\n",
    "- 입력 축제(또는 매칭명) 제외\n",
    "- 분류 우선순위: dataset ▶ rule ▶ llm(선택)\n",
    "- 출력:\n",
    "    1) 탐지된 [대/중/세부] 유형 (+근거)\n",
    "    2) 동일 (세부→중→대) 유형 축제 수\n",
    "    3) 동일 유형 축제 목록(이름만)\n",
    "\"\"\"\n",
    "\n",
    "import os, re, json\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "from difflib import get_close_matches\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ---------------- Env / OpenAI (선택) ----------------\n",
    "load_dotenv()\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-4o-mini\")\n",
    "\n",
    "_client_mode = None\n",
    "try:\n",
    "    from openai import OpenAI  # >=1.x\n",
    "    _client = OpenAI()\n",
    "    _client_mode = \"new\"\n",
    "except Exception:\n",
    "    try:\n",
    "        import openai               # <=0.x\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "        _client = openai\n",
    "        _client_mode = \"legacy\"\n",
    "    except Exception:\n",
    "        _client = None\n",
    "        _client_mode = None\n",
    "\n",
    "# ---------------- 파일 경로 ----------------\n",
    "CANDIDATE_FILES = [\n",
    "    \"./csv/2024.csv\",\n",
    "    \"./csv/2025.csv\",\n",
    "    \"/mnt/data/2024.csv\",\n",
    "    \"/mnt/data/2025.csv\",\n",
    "]\n",
    "\n",
    "# ---------------- 분류 체계 ----------------\n",
    "ALLOWED_MAJOR = [\"문화예술\", \"자연생태\", \"전통역사\", \"지역특산물\"]\n",
    "\n",
    "# 세부 규칙(키워드) : 나비/반딧불 ⇒ '곤충'로 흡수\n",
    "FINE_RULES: Dict[str, Dict[str, List[str]]] = {\n",
    "    \"자연생태\": {\n",
    "        \"꽃\": [\"꽃\",\"벚꽃\",\"장미\",\"튤립\",\"코스모스\",\"유채\",\"단풍\",\"억새\"],\n",
    "        \"곤충\": [\"곤충\",\"나비\",\"반딧불\",\"애벌레\",\"잠자리\",\"사슴벌레\"],\n",
    "        \"조류·철새\": [\"철새\",\"두루미\",\"기러기\",\"물새\",\"갈매기\"],\n",
    "        \"천문·별\": [\"천문\",\"별\",\"은하\",\"유성\",\"천체\",\"야경\"],\n",
    "        \"숲·생태원\": [\"생태\",\"습지\",\"숲\",\"수목원\",\"자연\",\"생태원\"],\n",
    "        \"산·계곡·물\": [\"산\",\"계곡\",\"호수\",\"강\",\"바다\",\"해변\",\"섬\"],\n",
    "    },\n",
    "    \"지역특산물\": {\n",
    "        \"과일\": [\"사과\",\"포도\",\"딸기\",\"수박\",\"밤\",\"복숭아\",\"자두\",\"귤\",\"매실\",\"블루베리\"],\n",
    "        \"곡물·채소\": [\"감자\",\"고구마\",\"고추\",\"옥수수\",\"쌀\",\"보리\",\"콩\",\"배추\",\"무\",\"양파\"],\n",
    "        \"수산·해산물\": [\"굴\",\"장어\",\"수산\",\"해산물\",\"전복\",\"낙지\",\"문어\",\"멍게\",\"새우\",\"게\",\"미역\",\"김\"],\n",
    "        \"축산\": [\"한우\",\"한돈\",\"우유\",\"치즈\",\"양고기\"],\n",
    "        \"주류\": [\"와인\",\"맥주\",\"막걸리\",\"전통주\",\"소주\",\"술\"],\n",
    "        \"디저트·카페\": [\"커피\",\"빵\",\"베이커리\",\"디저트\",\"케이크\",\"초코\",\"쿠키\"],\n",
    "        \"발효·김치\": [\"김치\",\"젓갈\",\"장\",\"된장\",\"고추장\",\"간장\",\"장아찌\"],\n",
    "    },\n",
    "    \"문화예술\": {\n",
    "        \"음악·콘서트\": [\"dj\",\"edm\",\"힙합\",\"랩\",\"kpop\",\"케이팝\",\"뮤직\",\"음악\",\"콘서트\",\"페스티벌\",\"재즈\",\"클래식\",\"버스킹\",\"합창\",\"연주\",\"오케스트라\"],\n",
    "        \"무용·댄스\": [\"댄스\",\"무용\",\"비보이\",\"댄싱\"],\n",
    "        \"연극·뮤지컬·영화\": [\"연극\",\"뮤지컬\",\"영화\",\"영화제\",\"시네마\"],\n",
    "        \"전시·미술·사진\": [\"전시\",\"미술\",\"아트\",\"사진\",\"비엔날레\",\"트리엔날레\"],\n",
    "        \"국악·전통공연\": [\"국악\",\"판소리\",\"사물놀이\",\"풍물\",\"탈춤\"],\n",
    "        \"시즌·겨울\": [\"산타\",\"크리스마스\",\"연말\",\"송년\"],\n",
    "    },\n",
    "    \"전통역사\": {\n",
    "        \"전통공예\": [\"도자기\",\"도예\",\"옹기\",\"한지\",\"서예\",\"목공\",\"금속공예\",\"염색\",\"옻칠\"],\n",
    "        \"유적·건축\": [\"한옥\",\"고택\",\"서원\",\"향교\",\"읍성\",\"성곽\",\"고분\",\"왕릉\",\"사찰\",\"궁\"],\n",
    "        \"민속·향토\": [\"전통\",\"전통축제\",\"민속\",\"향토\",\"세시\",\"의례\",\"단오\",\"정월대보름\",\"풍어제\",\"당산제\"],\n",
    "        \"무형문화재\": [\"무형문화재\",\"국가무형문화재\",\"전승\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# 역매핑(세부 → 대)\n",
    "FINE_TO_MAJOR = {fine: major for major, bucket in FINE_RULES.items() for fine in bucket.keys()}\n",
    "\n",
    "# ---------------- 유틸 ----------------\n",
    "def normalize_text(s: str) -> str:\n",
    "    if s is None: return \"\"\n",
    "    s = str(s).strip().replace(\"\\xa0\", \" \")\n",
    "    return re.sub(r\"\\s+\", \"\", s)\n",
    "\n",
    "def parse_date_str(s: str) -> Optional[pd.Timestamp]:\n",
    "    return pd.to_datetime(str(s), errors=\"coerce\", format=\"%Y-%m-%d\")\n",
    "\n",
    "def today_floor_ts() -> pd.Timestamp:\n",
    "    return pd.Timestamp.today().normalize()\n",
    "\n",
    "# 동의어를 표준 컬럼명으로 정규화\n",
    "COL_SYNONYMS = {\n",
    "    \"연번\": [\"연번\", \"번호\", \"id\", \"ID\"],\n",
    "    \"광역\": [\"광역자치단체명\",\"광역\",\"시도\",\"광역시도\",\"광역명\"],\n",
    "    \"기초\": [\"기초자치단체명\",\"기초\",\"시군구\",\"자치구\",\"기초명\"],\n",
    "    \"축제명\": [\"축제명\",\"행사명\",\"이벤트명\",\"명칭\",\"타이틀\"],\n",
    "    \"시작일\": [\"시작일\",\"start\",\"시작\",\"start_date\",\"시작일자\",\"개막일\"],\n",
    "    \"종료일\": [\"종료일\",\"end\",\"종료\",\"end_date\",\"종료일자\",\"폐막일\"],\n",
    "    \"대분류\": [\"대분류\",\"분류대\",\"유형대\",\"축제유형(대)\",\"축제유형_대\",\"분류_대\",\"대분류명\"],\n",
    "    \"중분류\": [\"중분류\",\"분류중\",\"유형중\",\"축제유형(중)\",\"축제유형_중\",\"분류_중\",\"중분류명\"],\n",
    "    \"세부분류\": [\"세부분류\",\"세부유형\",\"소분류\",\"세부분류\",\"분류소\",\"유형세부\",\"축제유형(세부)\",\"축제유형_세부\",\"세부분류명\"],\n",
    "    # 구버전 단일열\n",
    "    \"구_축제유형\": [\"축제유형\",\"축제 유형\"],\n",
    "}\n",
    "\n",
    "def _pick_first_exist(colnames: List[str], df_cols: List[str]) -> Optional[str]:\n",
    "    s = set(df_cols)\n",
    "    for c in colnames:\n",
    "        if c in s: return c\n",
    "    return None\n",
    "\n",
    "def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    mapping = {}\n",
    "    cols = [str(c).strip() for c in df.columns]\n",
    "    for std, synonyms in COL_SYNONYMS.items():\n",
    "        found = _pick_first_exist(synonyms, cols)\n",
    "        if found:\n",
    "            mapping[found] = std\n",
    "    out = df.rename(columns=mapping).copy()\n",
    "    # 표준 컬럼이 없으면 빈 컬럼 추가\n",
    "    for need in [\"연번\",\"광역\",\"기초\",\"축제명\",\"시작일\",\"종료일\",\"대분류\",\"중분류\",\"세부분류\",\"구_축제유형\"]:\n",
    "        if need not in out.columns:\n",
    "            out[need] = \"\"\n",
    "    # 구버전 단일열(축제유형) → 대분류/세부분류 추정\n",
    "    if out[\"구_축제유형\"].astype(str).str.strip().ne(\"\").mean() > 0:\n",
    "        # 값이 대부분 ALLOWED_MAJOR면 대분류로, 아니면 세부분류로 간주\n",
    "        vals = out[\"구_축제유형\"].astype(str).str.strip()\n",
    "        ratio_major = vals.isin(ALLOWED_MAJOR).mean()\n",
    "        if ratio_major >= 0.6:\n",
    "            out.loc[out[\"대분류\"].eq(\"\"), \"대분류\"] = vals\n",
    "        else:\n",
    "            out.loc[out[\"세부분류\"].eq(\"\"), \"세부분류\"] = vals\n",
    "    # 세부분류 → 대분류 자동 채움(룰 테이블 기준)\n",
    "    miss_major = out[\"대분류\"].astype(str).str.strip().eq(\"\")\n",
    "    guess = out.loc[miss_major, \"세부분류\"].map(lambda x: FINE_TO_MAJOR.get(str(x).strip(), \"\"))\n",
    "    out.loc[miss_major & guess.astype(bool), \"대분류\"] = guess\n",
    "    return out\n",
    "\n",
    "def ensure_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    needed = [\"연번\",\"광역\",\"기초\",\"축제명\",\"시작일\",\"종료일\",\"대분류\",\"중분류\",\"세부분류\"]\n",
    "    for c in needed:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"필수 컬럼 누락: {c}\")\n",
    "    return df\n",
    "\n",
    "def read_many_csv(paths: List[str]) -> pd.DataFrame:\n",
    "    frames = []\n",
    "    for p in paths:\n",
    "        if Path(p).exists():\n",
    "            try:\n",
    "                df = pd.read_csv(p, dtype=str).fillna(\"\")\n",
    "            except UnicodeDecodeError:\n",
    "                df = pd.read_csv(p, dtype=str, encoding=\"utf-8-sig\").fillna(\"\")\n",
    "            df[\"_출처파일\"] = Path(p).name\n",
    "            df = standardize_columns(df)\n",
    "            df = ensure_columns(df)\n",
    "            # 혹시 남아있는 '주민화합'은 제거\n",
    "            mask = ~(\n",
    "                df[\"대분류\"].astype(str).str.contains(\"주민화합\", na=False) |\n",
    "                df[\"중분류\"].astype(str).str.contains(\"주민화합\", na=False) |\n",
    "                df[\"세부분류\"].astype(str).str.contains(\"주민화합\", na=False)\n",
    "            )\n",
    "            df = df[mask]\n",
    "            frames.append(df)\n",
    "    if not frames:\n",
    "        raise FileNotFoundError(\"입력 CSV를 하나도 찾지 못했습니다.\")\n",
    "    out = pd.concat(frames, ignore_index=True)\n",
    "    out = out.drop_duplicates(\n",
    "        subset=[\"광역\",\"기초\",\"축제명\",\"대분류\",\"중분류\",\"세부분류\",\"시작일\",\"종료일\"],\n",
    "        keep=\"first\"\n",
    "    ).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "# ---------------- 분류(데이터셋/규칙/LLM) ----------------\n",
    "def _extract_json(text: str) -> Optional[dict]:\n",
    "    if not text: return None\n",
    "    m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n",
    "    if not m: return None\n",
    "    try:\n",
    "        return json.loads(m.group(0))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def dataset_detect(df: pd.DataFrame, name: str) -> Tuple[str,str,str, dict]:\n",
    "    \"\"\"데이터셋에서 [대,중,세부]를 찾아서 반환. 없으면 빈 문자열.\"\"\"\n",
    "    exact = df[df[\"축제명\"].astype(str).str.strip() == name.strip()]\n",
    "    if exact.empty:\n",
    "        # 부분 포함\n",
    "        nname = normalize_text(name)\n",
    "        cand = df[df[\"축제명\"].astype(str).apply(lambda x: normalize_text(x).find(nname) >= 0 or nname.find(normalize_text(x)) >= 0)]\n",
    "        if not cand.empty:\n",
    "            exact = cand\n",
    "        else:\n",
    "            # 유사도 매칭\n",
    "            hits = get_close_matches(name, df[\"축제명\"].astype(str).tolist(), n=1, cutoff=0.75)\n",
    "            if hits:\n",
    "                exact = df[df[\"축제명\"] == hits[0]]\n",
    "\n",
    "    if exact.empty:\n",
    "        return \"\",\"\",\"\", {}\n",
    "\n",
    "    row = exact.iloc[0]\n",
    "    major = str(row.get(\"대분류\",\"\")).strip()\n",
    "    mid   = str(row.get(\"중분류\",\"\")).strip()\n",
    "    fine  = str(row.get(\"세부분류\",\"\")).strip()\n",
    "\n",
    "    ev = {\n",
    "        \"source\": \"dataset\",\n",
    "        \"file\": str(row.get(\"_출처파일\",\"\")),\n",
    "        \"연번\": str(row.get(\"연번\",\"\")),\n",
    "        \"matched_name\": str(row.get(\"축제명\",\"\")),\n",
    "    }\n",
    "    return major, mid, fine, ev\n",
    "\n",
    "def collect_rule_hits(name: str) -> Dict[str, Dict[str, List[str]]]:\n",
    "    nm = (name or \"\").lower()\n",
    "    nm_plain = re.sub(r\"\\s+\", \"\", nm)\n",
    "    hits: Dict[str, Dict[str, List[str]]] = {}\n",
    "    for major, bucket in FINE_RULES.items():\n",
    "        for fine, kws in bucket.items():\n",
    "            for kw in kws:\n",
    "                k = kw.lower()\n",
    "                if (k in nm) or (k in nm_plain):\n",
    "                    hits.setdefault(major, {}).setdefault(fine, [])\n",
    "                    if kw not in hits[major][fine]:\n",
    "                        hits[major][fine].append(kw)\n",
    "    return hits\n",
    "\n",
    "def rule_detect(name: str) -> Tuple[str,str,dict]:\n",
    "    \"\"\"규칙으로 [대,세부] 추정\"\"\"\n",
    "    hits = collect_rule_hits(name)\n",
    "    if not hits: return \"\",\"\", {}\n",
    "    # 점수화: fine hit 수가 가장 큰 조합\n",
    "    best = None\n",
    "    best_score = -1\n",
    "    for major, fine_map in hits.items():\n",
    "        for fine, kws in fine_map.items():\n",
    "            score = len(kws)\n",
    "            if score > best_score:\n",
    "                best = (major, fine, kws)\n",
    "                best_score = score\n",
    "    if best is None: return \"\",\"\", {}\n",
    "    major, fine, kws = best\n",
    "    ev = {\"source\":\"rule\",\"major\":major,\"fine\":fine,\"hits\":\", \".join(kws)}\n",
    "    return major, fine, ev\n",
    "\n",
    "def llm_detect(name: str, allowed_fine: List[str], allowed_major: List[str]) -> Tuple[str,str,dict]:\n",
    "    if _client_mode is None or _client is None:\n",
    "        return \"\",\"\", {}\n",
    "    allowed_fine = sorted(list({f for f in allowed_fine if f and f not in [\"-\", \"\"]}))[:60]  # 안전상 60개 제한\n",
    "    majors_str = \"|\".join(allowed_major)\n",
    "    fines_str  = \"|\".join(allowed_fine) if allowed_fine else \"\"\n",
    "    prompt = f\"\"\"\n",
    "한국 축제명: \"{name}\"\n",
    "\n",
    "아래 JSON만 출력:\n",
    "{{\n",
    "  \"major\": \"{majors_str}\",\n",
    "  \"fine\": \"{fines_str if fines_str else '<없으면 빈 문자열>'}\",\n",
    "  \"hint_keywords\": [\"<이름에서 포착한 힌트 단어 최대 3개>\"]\n",
    "}}\n",
    "규칙:\n",
    "- major는 반드시 위 4개 중 하나(문화예술/자연생태/전통역사/지역특산물)\n",
    "- fine은 제공된 목록에서 고르되, 적합한게 없으면 \"\"(빈 문자열)\n",
    "- 설명문 금지. JSON만.\n",
    "\"\"\"\n",
    "    try:\n",
    "        if _client_mode == \"new\":\n",
    "            resp = _client.chat.completions.create(\n",
    "                model=OPENAI_MODEL,\n",
    "                messages=[\n",
    "                    {\"role\":\"system\",\"content\":\"Return ONLY compact JSON.\"},\n",
    "                    {\"role\":\"user\",\"content\":prompt},\n",
    "                ],\n",
    "                temperature=0, max_tokens=80,\n",
    "            )\n",
    "            content = resp.choices[0].message.content.strip()\n",
    "        else:\n",
    "            resp = _client.ChatCompletion.create(\n",
    "                model=OPENAI_MODEL,\n",
    "                messages=[\n",
    "                    {\"role\":\"system\",\"content\":\"Return ONLY compact JSON.\"},\n",
    "                    {\"role\":\"user\",\"content\":prompt},\n",
    "                ],\n",
    "                temperature=0, max_tokens=80,\n",
    "            )\n",
    "            content = resp[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        data = _extract_json(content) or {}\n",
    "        major = str(data.get(\"major\",\"\")).strip()\n",
    "        fine  = str(data.get(\"fine\",\"\")).strip()\n",
    "        hints = data.get(\"hint_keywords\", [])\n",
    "        if not isinstance(hints, list): hints = []\n",
    "        ev = {\"source\":\"llm\",\"major\":major,\"fine\":fine,\"hints\":\", \".join(map(str,hints))}\n",
    "        return major, fine, ev\n",
    "    except Exception:\n",
    "        return \"\",\"\", {}\n",
    "\n",
    "# ---------------- 파이프라인 ----------------\n",
    "def detect_labels(df: pd.DataFrame, name: str) -> Tuple[str,str,str,dict]:\n",
    "    \"\"\"[대,중,세부, Evidence]\"\"\"\n",
    "    major, mid, fine, ev = dataset_detect(df, name)\n",
    "    if major or mid or fine:\n",
    "        # 세부가 비었는데 데이터에 중분류만 있으면 fine<-중으로 승격\n",
    "        if fine == \"\" and mid != \"\":\n",
    "            fine = mid\n",
    "        return major, mid, fine, {\"source\":\"dataset\", **ev}\n",
    "\n",
    "    # 규칙\n",
    "    r_major, r_fine, r_ev = rule_detect(name)\n",
    "    if r_major or r_fine:\n",
    "        # mid는 아직 모르면 빈칸\n",
    "        return r_major, \"\", r_fine, r_ev\n",
    "\n",
    "    # LLM (선택)\n",
    "    allowed_fine = sorted(df[\"세부분류\"].astype(str).str.strip().unique().tolist())\n",
    "    l_major, l_fine, l_ev = llm_detect(name, allowed_fine, ALLOWED_MAJOR)\n",
    "    if l_major or l_fine:\n",
    "        return l_major, \"\", l_fine, l_ev\n",
    "\n",
    "    return \"\",\"\",\"\", {\"source\":\"none\"}\n",
    "\n",
    "def filter_same_group(df: pd.DataFrame, name: str, major: str, mid: str, fine: str) -> pd.DataFrame:\n",
    "    \"\"\"동일 '세부→중→대' 그룹에서, 오늘 이전 시작 축제만, 자기 자신 제외\"\"\"\n",
    "    base = df.copy()\n",
    "    # 우선순위: 세부 > 중 > 대\n",
    "    if fine:\n",
    "        mask = base[\"세부분류\"].astype(str).str.strip() == fine\n",
    "    elif mid:\n",
    "        mask = base[\"중분류\"].astype(str).str.strip() == mid\n",
    "    else:\n",
    "        mask = base[\"대분류\"].astype(str).str.strip() == major\n",
    "    same = base[mask].copy()\n",
    "\n",
    "    # 아직 시작 안 한 축제 제외\n",
    "    today = today_floor_ts()\n",
    "    same[\"_시작\"] = pd.to_datetime(same[\"시작일\"], errors=\"coerce\")\n",
    "    same = same[(~same[\"_시작\"].isna()) & (same[\"_시작\"] <= today)]\n",
    "\n",
    "    # 자기 자신 제외(이름 정규화)\n",
    "    inorm = normalize_text(name)\n",
    "    same = same[ same[\"축제명\"].astype(str).apply(lambda x: normalize_text(x) != inorm) ]\n",
    "\n",
    "    same = same.sort_values(by=[\"광역\",\"기초\",\"축제명\"]).drop(columns=[\"_시작\"], errors=\"ignore\")\n",
    "    return same[[\"연번\",\"광역\",\"기초\",\"축제명\",\"대분류\",\"중분류\",\"세부분류\",\"시작일\",\"종료일\",\"_출처파일\"]]\n",
    "\n",
    "def run(festival_name: str, print_limit: int = 300, dedupe: bool = True):\n",
    "    # 데이터 로드\n",
    "    df = read_many_csv(CANDIDATE_FILES)\n",
    "\n",
    "    # 라벨 탐지\n",
    "    major, mid, fine, ev = detect_labels(df, festival_name)\n",
    "\n",
    "    # 출력 헤더\n",
    "    print(f\"입력 축제명: {festival_name}\")\n",
    "    if fine or mid or major:\n",
    "        print(f\"탐지된 유형: 대='{major or '-'}' | 중='{mid or '-'}' | 세부='{fine or '-'}'  | 출처: {ev.get('source','-')}\")\n",
    "    else:\n",
    "        print(\"탐지된 유형: (탐지 실패)\")\n",
    "    # 근거\n",
    "    src = ev.get(\"source\",\"-\")\n",
    "    if src == \"dataset\":\n",
    "        print(f\"근거(dataset): 파일={ev.get('file','')}, 연번={ev.get('연번','')}, 매칭명={ev.get('matched_name','')}\")\n",
    "    elif src == \"rule\":\n",
    "        print(f\"근거(rule): major='{ev.get('major','')}', fine='{ev.get('fine','')}', 히트=[{ev.get('hits','')}]\")\n",
    "    elif src == \"llm\":\n",
    "        print(f\"근거(llm): major='{ev.get('major','')}', fine='{ev.get('fine','')}', 힌트=[{ev.get('hints','')}]\")\n",
    "    else:\n",
    "        print(\"근거: -\")\n",
    "\n",
    "    # 동일 그룹 추출\n",
    "    same = filter_same_group(df, festival_name, major, mid, fine)\n",
    "\n",
    "    if same.empty:\n",
    "        print(\"\\n동일 유형 축제 수: 0\")\n",
    "        return df, same\n",
    "\n",
    "    if dedupe:\n",
    "        same = same.drop_duplicates(subset=[\"축제명\"], keep=\"first\")\n",
    "\n",
    "    # 리스트 출력(이름만)\n",
    "    names = same.sort_values(by=[\"시작일\",\"축제명\"])\n",
    "    names_list = names[\"축제명\"].astype(str).tolist()\n",
    "\n",
    "    print(f\"\\n동일 유형 축제 수: {len(names_list)}\")\n",
    "    print(\"\\n[동일 유형 축제 목록]\")\n",
    "    for i, nm in enumerate(names_list[:print_limit], start=1):\n",
    "        print(f\"{i:>3}. {nm}\")\n",
    "    if len(names_list) > print_limit:\n",
    "        print(f\"... ({len(names_list) - print_limit}개 더 있음)\")\n",
    "\n",
    "    return df, same\n",
    "\n",
    "# ------------- Example -------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 예시: 이름만 바꿔 테스트\n",
    "    _df, _same = run(\"담양산타축제\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv_festival",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
