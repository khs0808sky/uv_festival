{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3424944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥ ì¶•ì œëª…: ë‹´ì–‘ì‚°íƒ€ì¶•ì œ\n",
      "ë§¤ì¹­ëœ ì¶•ì œëª…(ì°¸ê³ ): ì œ7íšŒ ë‹´ì–‘ì‚°íƒ€ì¶•ì œ\n",
      "íƒì§€ëœ ì¶•ì œìœ í˜•: ë¬¸í™”ì˜ˆìˆ \n",
      "ì…ë ¥ëª…ê³¼ ë§¤ì¹­ëœ í–‰ ìˆ˜: 2\n",
      "ë™ì¼ ìœ í˜• ì¶•ì œ ìˆ˜: 294\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "ğŸ¯ LangGraph íŒŒì´í”„ë¼ì¸: ì¶•ì œëª… â†’ ì¶•ì œìœ í˜• íƒì§€ â†’ ë™ì¼ ìœ í˜• ì¶•ì œ ë¦¬ìŠ¤íŠ¸\n",
    "- ë‚ ì§œëŠ” ë¬´ì‹œí•©ë‹ˆë‹¤ (ìš”ì²­ì‚¬í•­ ë°˜ì˜).\n",
    "- LangGraph .invoke() ê²°ê³¼(dict)ë¥¼ FestStateë¡œ ì¬ë³€í™˜í•˜ì—¬ AttributeError í•´ê²°.\n",
    "\n",
    "ì‚¬ìš©ë²•(ë…¸íŠ¸ë¶ ì…€):\n",
    "1) ì´ ì½”ë“œë¥¼ í•œ ì…€ì— ë¶™ì—¬ë„£ê³  ì‹¤í–‰\n",
    "2) ë§ˆì§€ë§‰ ë¶€ë¶„ ì˜ˆì‹œ:\n",
    "    USER_FESTIVAL_NAME = \"ë‹´ì–‘ì‚°íƒ€ì¶•ì œ\"\n",
    "    result_state = run_pipeline(USER_FESTIVAL_NAME)\n",
    "    display(result_state.same_type_df.head(50))\n",
    "\n",
    "í•„ìš” íŒ¨í‚¤ì§€(í•œë²ˆë§Œ):\n",
    "%pip install langgraph pydantic pandas\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import Optional, Tuple, List, Any\n",
    "from difflib import get_close_matches\n",
    "from pathlib import Path\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "# Pydantic v2ì—ì„œ DataFrame ê°™ì€ ì„ì˜ íƒ€ì… í—ˆìš© ì„¤ì •\n",
    "try:\n",
    "    from pydantic import ConfigDict  # v2\n",
    "except ImportError:\n",
    "    ConfigDict = None\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# CSV í›„ë³´ ê²½ë¡œ (ìƒìœ„ì—ì„œë¶€í„° ì¡´ì¬í•˜ëŠ” ì²« íŒŒì¼ ì‚¬ìš©)\n",
    "# ----------------------------------------------------\n",
    "CANDIDATE_PATHS: List[str] = [\n",
    "    \"./csv/ì¶•ì œ_í•µì‹¬í•„ë“œ_ë‚ ì§œì™„ë¹„_noì§€ì—­.csv\",\n",
    "    \"./csv/ì¶•ì œ_í•µì‹¬í•„ë“œ_ë‚ ì§œì™„ë¹„.csv\",\n",
    "    \"./csv/ì¶•ì œ_í•µì‹¬í•„ë“œ.csv\",\n",
    "    \"/mnt/data/csv/ì¶•ì œ_í•µì‹¬í•„ë“œ_ë‚ ì§œì™„ë¹„_noì§€ì—­.csv\",\n",
    "    \"/mnt/data/csv/ì¶•ì œ_í•µì‹¬í•„ë“œ_ë‚ ì§œì™„ë¹„.csv\",\n",
    "    \"/mnt/data/csv/ì¶•ì œ_í•µì‹¬í•„ë“œ.csv\",\n",
    "    \"/mnt/data/ì¶•ì œ_í•µì‹¬í•„ë“œ_ë‚ ì§œì™„ë¹„_noì§€ì—­.csv\",\n",
    "    \"/mnt/data/ì¶•ì œ_í•µì‹¬í•„ë“œ_ë‚ ì§œì™„ë¹„.csv\",\n",
    "    \"/mnt/data/ì¶•ì œ_í•µì‹¬í•„ë“œ.csv\",\n",
    "]\n",
    "\n",
    "ALLOWED_TYPES = [\"ë¬¸í™”ì˜ˆìˆ \", \"ì§€ì—­íŠ¹ì‚°ë¬¼\", \"ì£¼ë¯¼í™”í•©\", \"ìì—°ìƒíƒœ\", \"ì „í†µì—­ì‚¬\"]\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# ìœ í‹¸ í•¨ìˆ˜\n",
    "# ---------------------------\n",
    "def resolve_csv_path(csv_path_override: Optional[str] = None) -> str:\n",
    "    \"\"\"ì§€ì • ê²½ë¡œê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ í›„ë³´ ëª©ë¡ì—ì„œ ì¡´ì¬í•˜ëŠ” ì²« íŒŒì¼ ì‚¬ìš©.\"\"\"\n",
    "    if csv_path_override and Path(csv_path_override).exists():\n",
    "        return csv_path_override\n",
    "    for p in CANDIDATE_PATHS:\n",
    "        if Path(p).exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\"CSV íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. CANDIDATE_PATHSë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = str(s).strip()\n",
    "    s = s.replace(\"\\xa0\", \" \")\n",
    "    return re.sub(r\"\\s+\", \"\", s)\n",
    "\n",
    "def ensure_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    needed = [\"ì—°ë²ˆ\", \"ê´‘ì—­ìì¹˜ë‹¨ì²´ëª…\", \"ê¸°ì´ˆìì¹˜ë‹¨ì²´ëª…\", \"ì¶•ì œëª…\", \"ì¶•ì œ ìœ í˜•\"]\n",
    "    for c in needed:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {c} (í˜„ì¬ ë³´ìœ : {list(df.columns)[:12]} ...)\")\n",
    "    return df\n",
    "\n",
    "def detect_type_from_name(df: pd.DataFrame, name: str) -> Tuple[str, int, str]:\n",
    "    \"\"\"\n",
    "    ì¶•ì œëª…ì„ ê¸°ì¤€ìœ¼ë¡œ 'ì¶•ì œ ìœ í˜•'ì„ ì°¾ëŠ”ë‹¤.\n",
    "    ë°˜í™˜: (íƒì§€ëœìœ í˜•, ë§¤ì¹­ëœí–‰ìˆ˜, ìµœì¢…ë§¤ì¹­ì¶•ì œëª…)\n",
    "    ë§¤ì¹­ ìˆœì„œ: ì •í™•ì¼ì¹˜ â†’ ë¶€ë¶„ì¼ì¹˜(ê³µë°±ë¬´ì‹œ) â†’ ìœ ì‚¬ë„(0.6)\n",
    "    \"\"\"\n",
    "    # 1) ì •í™• ì¼ì¹˜\n",
    "    exact = df[df[\"ì¶•ì œëª…\"].astype(str).str.strip() == name.strip()]\n",
    "    if not exact.empty:\n",
    "        t = str(exact.iloc[0][\"ì¶•ì œ ìœ í˜•\"])\n",
    "        return t, len(exact), str(exact.iloc[0][\"ì¶•ì œëª…\"])\n",
    "\n",
    "    # 2) ë¶€ë¶„ í¬í•¨ (ê³µë°± ì œê±° í›„)\n",
    "    nname = normalize_text(name)\n",
    "    cand = df[df[\"ì¶•ì œëª…\"].astype(str).apply(lambda x: normalize_text(x) in nname or nname in normalize_text(x))]\n",
    "    if not cand.empty:\n",
    "        t = str(cand.iloc[0][\"ì¶•ì œ ìœ í˜•\"])\n",
    "        return t, len(cand), str(cand.iloc[0][\"ì¶•ì œëª…\"])\n",
    "\n",
    "    # 3) ìœ ì‚¬ë„(ìƒìœ„ 1ê°œ)\n",
    "    all_names = df[\"ì¶•ì œëª…\"].astype(str).tolist()\n",
    "    hits = get_close_matches(name, all_names, n=1, cutoff=0.6)\n",
    "    if hits:\n",
    "        row = df[df[\"ì¶•ì œëª…\"] == hits[0]].iloc[0]\n",
    "        return str(row[\"ì¶•ì œ ìœ í˜•\"]), 1, str(row[\"ì¶•ì œëª…\"])\n",
    "\n",
    "    return \"\", 0, \"\"\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# LangGraph ìƒíƒœ/ë…¸ë“œ\n",
    "# ---------------------------\n",
    "class FestState(BaseModel):\n",
    "    # âœ… Pydantic ì„¤ì • (DataFrame ê°™ì€ ì„ì˜ íƒ€ì… í—ˆìš©)\n",
    "    if ConfigDict is not None:\n",
    "        model_config = ConfigDict(arbitrary_types_allowed=True)  # Pydantic v2\n",
    "    else:\n",
    "        class Config:  # Pydantic v1 fallback\n",
    "            arbitrary_types_allowed = True\n",
    "\n",
    "    # ì…ë ¥\n",
    "    query_name: str = Field(\"\", description=\"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¶•ì œëª…\")\n",
    "    csv_path_override: Optional[str] = None\n",
    "\n",
    "    # ë‚´ë¶€ (DataFrameì€ ì„ì˜ íƒ€ì…ì´ë¯€ë¡œ ìœ„ ì˜µì…˜ í•„ìš”)\n",
    "    df: Optional[pd.DataFrame] = None\n",
    "    detected_type: str = \"\"\n",
    "    detected_row_count: int = 0\n",
    "    matched_name: str = \"\"\n",
    "\n",
    "    # ì¶œë ¥\n",
    "    same_type_df: Optional[pd.DataFrame] = None\n",
    "\n",
    "\n",
    "def node_load_data(state: FestState) -> FestState:\n",
    "    path = resolve_csv_path(state.csv_path_override)\n",
    "    df = pd.read_csv(path, dtype=str).fillna(\"\")\n",
    "    state.df = ensure_columns(df)\n",
    "    return state\n",
    "\n",
    "\n",
    "def node_detect_type(state: FestState) -> FestState:\n",
    "    assert state.df is not None, \"ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
    "    dtype, cnt, mname = detect_type_from_name(state.df, state.query_name)\n",
    "    state.detected_type = dtype\n",
    "    state.detected_row_count = cnt\n",
    "    state.matched_name = mname\n",
    "    return state\n",
    "\n",
    "\n",
    "def node_filter_same_type(state: FestState) -> FestState:\n",
    "    assert state.df is not None, \"ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
    "    if not state.detected_type:\n",
    "        state.same_type_df = pd.DataFrame()\n",
    "        return state\n",
    "\n",
    "    same = state.df[state.df[\"ì¶•ì œ ìœ í˜•\"].astype(str).str.strip() == state.detected_type.strip()].copy()\n",
    "\n",
    "    # ë³´ê¸° ì¢‹ê²Œ ì •ë ¬\n",
    "    same = same.sort_values(by=[\"ê´‘ì—­ìì¹˜ë‹¨ì²´ëª…\", \"ê¸°ì´ˆìì¹˜ë‹¨ì²´ëª…\", \"ì¶•ì œëª…\"], ascending=[True, True, True])\n",
    "\n",
    "    # ì¶œë ¥ ì»¬ëŸ¼(ìš”êµ¬ì‚¬í•­: ë‚ ì§œ ë¬´ì‹œ)\n",
    "    state.same_type_df = same[[\"ì—°ë²ˆ\", \"ê´‘ì—­ìì¹˜ë‹¨ì²´ëª…\", \"ê¸°ì´ˆìì¹˜ë‹¨ì²´ëª…\", \"ì¶•ì œëª…\", \"ì¶•ì œ ìœ í˜•\"]]\n",
    "    return state\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# ê·¸ë˜í”„ êµ¬ì„± & ì‹¤í–‰ í—¬í¼\n",
    "# ---------------------------\n",
    "def build_app():\n",
    "    graph = StateGraph(FestState)\n",
    "    graph.add_node(\"load_data\", node_load_data)\n",
    "    graph.add_node(\"detect_type\", node_detect_type)\n",
    "    graph.add_node(\"filter_same_type\", node_filter_same_type)\n",
    "\n",
    "    graph.add_edge(START, \"load_data\")\n",
    "    graph.add_edge(\"load_data\", \"detect_type\")\n",
    "    graph.add_edge(\"detect_type\", \"filter_same_type\")\n",
    "    graph.add_edge(\"filter_same_type\", END)\n",
    "\n",
    "    return graph.compile()\n",
    "\n",
    "\n",
    "APP = build_app()\n",
    "\n",
    "\n",
    "def _to_state(obj) -> FestState:\n",
    "    \"\"\"LangGraph .invoke() ê°€ dictë¥¼ ë°˜í™˜í•˜ëŠ” ê²½ìš° FestStateë¡œ ë³€í™˜.\"\"\"\n",
    "    if isinstance(obj, FestState):\n",
    "        return obj\n",
    "    try:\n",
    "        # Pydantic v2\n",
    "        return FestState.model_validate(obj)  # type: ignore[attr-defined]\n",
    "    except Exception:\n",
    "        try:\n",
    "            # Pydantic v1\n",
    "            return FestState.parse_obj(obj)  # type: ignore[attr-defined]\n",
    "        except Exception:\n",
    "            return FestState(**obj)  # ìµœí›„ ìˆ˜ë‹¨\n",
    "\n",
    "\n",
    "def run_pipeline(festival_name: str, csv_path_override: Optional[str] = None) -> FestState:\n",
    "    \"\"\"\n",
    "    ê°„í¸ ì‹¤í–‰:\n",
    "      state = run_pipeline(\"ë‹´ì–‘ì‚°íƒ€ì¶•ì œ\")\n",
    "      display(state.same_type_df.head(50))\n",
    "    \"\"\"\n",
    "    init = FestState(query_name=festival_name, csv_path_override=csv_path_override)\n",
    "    # LangGraphëŠ” ê²°ê³¼ë¥¼ dictë¡œ ë°˜í™˜í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³€í™˜\n",
    "    raw = APP.invoke(init)\n",
    "    final_state = _to_state(raw)\n",
    "\n",
    "    # ì½˜ì†” ìš”ì•½\n",
    "    print(\"ì…ë ¥ ì¶•ì œëª…:\", festival_name)\n",
    "    print(\"ë§¤ì¹­ëœ ì¶•ì œëª…(ì°¸ê³ ):\", final_state.matched_name or \"(ì—†ìŒ)\")\n",
    "    print(\"íƒì§€ëœ ì¶•ì œìœ í˜•:\", final_state.detected_type or \"(íƒì§€ ì‹¤íŒ¨)\")\n",
    "    print(\"ì…ë ¥ëª…ê³¼ ë§¤ì¹­ëœ í–‰ ìˆ˜:\", final_state.detected_row_count)\n",
    "    print(\"ë™ì¼ ìœ í˜• ì¶•ì œ ìˆ˜:\", (0 if final_state.same_type_df is None else len(final_state.same_type_df)))\n",
    "\n",
    "    return final_state\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# ìŠ¤í¬ë¦½íŠ¸ë¡œ ì§ì ‘ ì‹¤í–‰ ì‹œ (ë…¸íŠ¸ë¶ì—ì„œë„ ë™ì‘)\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    USER_FESTIVAL_NAME = \"ë‹´ì–‘ì‚°íƒ€ì¶•ì œ\"\n",
    "    state = run_pipeline(USER_FESTIVAL_NAME)\n",
    "    # ê²°ê³¼ ì €ì¥ì„ ì›í•˜ë©´ ì£¼ì„ í•´ì œ\n",
    "    # if state.same_type_df is not None and not state.same_type_df.empty:\n",
    "    #     out = Path(\"./ë™ì¼ìœ í˜•_ì „ì²´ëª©ë¡.csv\")\n",
    "    #     state.same_type_df.to_csv(out, index=False, encoding=\"utf-8-sig\")\n",
    "    #     print(\"ì €ì¥:\", out.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv_festival",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
